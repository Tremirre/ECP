{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Computation - Assignment 1: Greedy Heuristics\n",
    "\n",
    "Bartosz Stachowiak 148259<br>\n",
    "Andrzej Kajdasz 148273"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement\n",
    "\n",
    "There were are columns of integers representing nodes. Each row corresponds to a node and contains its x and y coordinates in a plane, as well as a cost associated with the node. There were 4 such data sets each consisting of 200 rows (each representing a single node).\n",
    "\n",
    "Problem to solve is to choose precisely 50% of the nodes (rounding up if there is an odd number of nodes) and create a Hamiltonian cycle (a closed path) using this subset of nodes. The goal is to minimize the combined total length of the path and the total cost of the selected nodes.\n",
    "\n",
    "To calculate the distances between nodes, the Euclidean distance formula was used and then round the results to the nearest integer. As suggested, the distances between the nodes were calculated after loading the data and placed in a matrix, so that during the subsequent evaluation of the problem, it was only necessary to read these values which reduced the cost of the operation of the algorithm.\n",
    "\n",
    "Three algorithms were used to solve the problem:\n",
    "\n",
    "- Random Solution\n",
    "- Nearest Neighbor\n",
    "- Greedy Cycle\n",
    "\n",
    "**Note**\n",
    "\n",
    "As we are optimizing not only for the distance, but also for weight, we have to use a different approach than the one presented in the lecture. We cannot simply choose the nearest neighbor, as it may be too expensive. Instead, we have to choose the cheapest neighbor that is not too far away. We have to use a greedy approach, but we have to be careful not to get stuck in a local minimum.\n",
    "\n",
    "Similarily in Greedy Cycle we have to consider the weight of the node, not only the distance, when evaluating the increase in cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pseudocode of all implemented algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Random Solution\n",
    "\n",
    "```\n",
    "function random_solution(nodes, seed, target_size):\n",
    "    set random seed to seed\n",
    "\n",
    "    indices := [0, 1, ..., len(nodes) - 1]\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    solution := indices[:target_size]\n",
    "    return solution\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Nearest Neighbor\n",
    "\n",
    ">Note that in our implementation, distance matrix is not passed as an argument, but a class member, calculated before the algorithm is run.\\\n",
    ">For simplification, here we pass it as an argument.\n",
    "\n",
    "```\n",
    "function nearest_neighbor_solution(nodes, start_index, target_size, distance_matrix):\n",
    "    solution := [start_index]\n",
    "    visited := [false, false, ..., false]\n",
    "    visited[start_index] := true\n",
    "\n",
    "    for i in 0..target_size - 1:\n",
    "        min_cost := infinity\n",
    "        min_index := -1\n",
    "        for j in 0..len(nodes) - 1:\n",
    "            if visited[j]:\n",
    "                continue\n",
    "            if distance_matrix[solution[i]][j] < min_cost:\n",
    "                min_cost := distance_matrix[solution[i]][j] + nodes[j].weight\n",
    "                min_index := j\n",
    "        solution.append(min_index)\n",
    "        visited[min_index] := true\n",
    "\n",
    "    return solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Greedy Cycle\n",
    "\n",
    ">Again, distance matrix passed as an argument.\n",
    "\n",
    "```\n",
    "function nearest_neighbor_solution(nodes, start_index, target_size, distance_matrix):\n",
    "    solution := [start_index]\n",
    "    visited := [false, false, ..., false]\n",
    "    visited[start_index] := true\n",
    "\n",
    "    // while solution is not complete, add nodes\n",
    "    while len(solution) < target_size:\n",
    "\n",
    "        min_increase := infinity\n",
    "        min_index := -1\n",
    "        insert_point := -1\n",
    "\n",
    "        if len(solution) == 1:\n",
    "            // find cheapest neighbor\n",
    "\n",
    "            for i in 0..len(nodes) - 1:\n",
    "                if visited[i]:\n",
    "                    continue\n",
    "                if nodes[i].weight < min_increase:\n",
    "                    min_increase := nodes[i].cost\n",
    "                    min_index := i\n",
    "\n",
    "            solution.append(min_index)\n",
    "            visited[min_index] := true\n",
    "            continue\n",
    "\n",
    "        for i in 0..len(nodes) - 1:\n",
    "            if visited[i]:\n",
    "                continue\n",
    "\n",
    "            // find cheapest place to insert\n",
    "            for j in 0..len(solution) - 1:\n",
    "                \n",
    "                next_idx := (j + 1) % len(solution)\n",
    "                added_distance := distance_matrix[solution[j]][i] + distance_matrix[i][solution[next_idx]]\n",
    "                removed_distance := distance_matrix[solution[j]][solution[next_idx]]\n",
    "                increase := added_distance + nodes[i].weight - removed_distance\n",
    "\n",
    "                if increase < min_increase:\n",
    "                    min_increase := increase\n",
    "                    min_index := i\n",
    "                    insert_point := j + 1\n",
    "        \n",
    "        solution.insert(insert_point, min_index)\n",
    "        visited[min_index] := true\n",
    "\n",
    "    return solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results of the computational experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Code for visualization of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/'\n",
    "RESULT_FOLDER = f'{DATA_FOLDER}results/'\n",
    "INSTANCE_FOLDER = f'{DATA_FOLDER}tsp_instances/'\n",
    "\n",
    "SOLVERS = {\n",
    "    'r': \"Random\",\n",
    "    'n': \"Nearest Neighbor\",\n",
    "    'g': \"Greedy Cycle\",\n",
    "}\n",
    "NUM_NODES = 200\n",
    "\n",
    "instance_files = [path for path in pathlib.Path(INSTANCE_FOLDER).iterdir() if path.is_file()]\n",
    "instance_names = [path.name.removesuffix('.csv') for path in instance_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_instance(path: str) -> np.ndarray[int]:\n",
    "    with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    instance = [\n",
    "        [\n",
    "            int(cell) for cell in line.split(';') if cell\n",
    "        ] for line in text.split('\\n') if line\n",
    "    ]\n",
    "    return np.array(instance)\n",
    "\n",
    "def read_solution(path: str) -> tuple[np.ndarray[int], int]:\n",
    "    with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    solution = [int(num.strip()) for num in text.split('\\n') if num]\n",
    "    return np.array(solution[:-1]), solution[-1]\n",
    "\n",
    "def plot_solution_for_instance(instance: np.ndarray[int], solution: np.ndarray[int], ax: plt.Axes) -> None:\n",
    "    solution = np.append(solution, solution[0])\n",
    "    ax.plot(instance[solution, 0], instance[solution, 1], c='r')\n",
    "    ax.scatter(instance[:, 0], instance[:, 1], s=instance[:, 2] / 20, c=instance[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_data = {\n",
    "    name: read_instance(f'{INSTANCE_FOLDER}{name}.csv')\n",
    "    for name in instance_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_solvers_pairs = itertools.product(instances_data.keys(), SOLVERS.keys())\n",
    "\n",
    "all_results = {}\n",
    "all_costs = {}\n",
    "all_stats = {}\n",
    "\n",
    "for instance, solver in instances_solvers_pairs:\n",
    "    all_results[instance] = all_results.get(instance, {})\n",
    "    all_costs[instance] = all_costs.get(instance, {})\n",
    "    all_stats[instance] = all_stats.get(instance, {})\n",
    "    costs = []\n",
    "    paring_results = []\n",
    "    for idx in range(NUM_NODES):\n",
    "        solution, cost = read_solution(f'{RESULT_FOLDER}{instance}-{solver}-{idx}.txt')\n",
    "        paring_results.append(solution)\n",
    "        costs.append(cost)\n",
    "    all_results[instance][solver] = np.array(paring_results)\n",
    "    all_costs[instance][solver] = np.array(costs)\n",
    "    all_stats[instance][solver] = {\n",
    "        'mean': np.mean(costs),\n",
    "        'std': np.std(costs),\n",
    "        'min': np.min(costs),\n",
    "        'max': np.max(costs),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame(all_stats).T\n",
    "max_df = pd.DataFrame(all_stats).T\n",
    "min_df = pd.DataFrame(all_stats).T\n",
    "\n",
    "for column in SOLVERS.keys():\n",
    "    mean_df[column] = mean_df[column].apply(lambda x: f'{x[\"mean\"]:.0f} ± {x[\"std\"]:.0f}')\n",
    "    max_df[column] = max_df[column].apply(lambda x: x['max'])\n",
    "    min_df[column] = min_df[column].apply(lambda x: x['min'])\n",
    "\n",
    "for df in [mean_df, max_df, min_df]:\n",
    "    df.rename(columns=SOLVERS, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Visualizations and statistics for all dataset-algorithm pairs\n",
    "\n",
    "In tabular form we present the Mean, Standard Deviation, Minimum and Maximum of the results of the algorithms for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean and std of the costs:\")\n",
    "mean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(instances_data.keys()), figsize=(15, 5), sharey=True)\n",
    "\n",
    "for idx, instance in enumerate(instances_data.keys()):\n",
    "    if idx == 0:\n",
    "        axs[idx].set_ylabel('Cost')\n",
    "    axs[idx].set_title(instance)\n",
    "    axs[idx].violinplot(\n",
    "        [all_costs[instance][solver] for solver in SOLVERS.keys()],\n",
    "        showmeans=True,\n",
    "    )\n",
    "    axs[idx].set_xticks(range(1, len(SOLVERS.keys()) + 1))\n",
    "    axs[idx].set_xticklabels(SOLVERS.values(), rotation=45, ha='right')\n",
    "\n",
    "plt.suptitle('Distribution of the costs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max of the costs:\")\n",
    "max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min of the costs:\")\n",
    "min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(instances_data.keys()), figsize=(15, 5), sharey=True)\n",
    "bar_width = 0.35\n",
    "\n",
    "for idx, instance in enumerate(instances_data.keys()):\n",
    "    if idx == 0:\n",
    "        axs[idx].set_ylabel('Cost')\n",
    "    axs[idx].set_title(instance)\n",
    "\n",
    "    axs[idx].bar(\n",
    "        np.arange(len(SOLVERS.keys())),\n",
    "        max_df.loc[instance].values,\n",
    "        width=bar_width,\n",
    "        label='Maximal cost',\n",
    "    )\n",
    "    axs[idx].bar(\n",
    "        np.arange(len(SOLVERS.keys())) + bar_width,\n",
    "        min_df.loc[instance].values,\n",
    "        width=bar_width,\n",
    "        label='Minimal cost',\n",
    "    )\n",
    "\n",
    "    axs[idx].set_xticks(np.arange(len(SOLVERS.keys())) + bar_width / 2)\n",
    "    axs[idx].set_xticklabels(SOLVERS.values(), rotation=45, ha='right')\n",
    "\n",
    "plt.suptitle('Maximal cost')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Best solutions for all datasets and algorithms\n",
    "\n",
    "To more easily compare the results, we present the best solutions for each dataset side by side.\n",
    "\n",
    "The weight of each node is denoted both by its size and color. The bigger and brighter the node, the higher its weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, instance in enumerate(instances_data.keys()):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    for solver_idx, solver in enumerate(SOLVERS.keys()):\n",
    "        best_instance_idx = np.argmin(all_costs[instance][solver])\n",
    "        plot_solution_for_instance(instances_data[instance], all_results[instance][solver][best_instance_idx], axs[solver_idx])\n",
    "        axs[solver_idx].set_title(f'{SOLVERS[solver]}: {all_costs[instance][solver][best_instance_idx]:.0f}')\n",
    "    fig.suptitle(f'Instance {instance}', fontsize=16, y=1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Visualization of solution search for both heuristics\n",
    "\n",
    "#### Nearest Neighbor\n",
    "\n",
    "![nn](../tmp/n-out-prog-a.gif)\n",
    "\n",
    "#### Greedy Cycle\n",
    "![gc](../tmp/g-out-prog-a.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Source Code\n",
    "\n",
    "[GitHub](https://github.com/Tremirre/ECP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusions\n",
    "\n",
    "Analyzing the results and visualizations, one can come to several conclusions about the algorithms used in the task:\n",
    "\n",
    "- Greedy methods are much better than the random node selection method. However, among them, there is a noticeable difference between greedy cycle and nearest neighbor.\n",
    "\n",
    "- The poor results of the random method are very easily explained. With a large number of nodes, the probability of choosing a good solution is very small, hence the poor performance.\n",
    "  \n",
    "- Both greedy methods achieved relatively good results, when comparing them to the random method. The Greedy Cycle approach seems to slightly outperform the Nearest Neighbors one. It is mainly due to the fact that at the end of the nearest neighbor algorithm, i.e. when the number of nodes in the path has already reached the required number, the last added node must be merged with the first one. This results in a very large distance being added to the final result (the edge connecting the first and last node added to the solution). The greedy cycle algorithm does not have the above disadvantage because from the very beginning the solution is created as a cycle, taking into account the overall increase in the cost of the solution.\n",
    "\n",
    "- Relatively low standard deviation of the results obtained in the greedy methods indicates that the algorithms are quite stable, more reliable than the random method.\n",
    "  \n",
    "- An important aspect in greedy methods is how the algorithm avoids nodes that have a very high cost. It often chooses vertices that are more distant but have much lower costs - which is clearly visible in the visualizations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
