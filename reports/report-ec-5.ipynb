{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd3jynF89haJ"
   },
   "source": [
    "# Evolutionary Computation - Assignment 5: The use of move evaluations (deltas) from previous iterations in local search\n",
    "\n",
    "Bartosz Stachowiak 148259<br>\n",
    "Andrzej Kajdasz 148273"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANGmPjsk9haM"
   },
   "source": [
    "## 1. Problem Statement\n",
    "\n",
    "There are columns of integers representing nodes. Each row corresponds to a node and contains its x and y coordinates in a plane, as well as a cost associated with the node. There were 4 such data sets each consisting of 200 rows (each representing a single node).\n",
    "\n",
    "Problem to solve is to choose precisely 50% of the nodes (rounding up if there is an odd number of nodes) and create a Hamiltonian cycle (a closed path) using this subset of nodes. The goal is to minimize the combined total length of the path and the total cost of the selected nodes.\n",
    "\n",
    "To calculate the distances between nodes, the Euclidean distance formula was used and then round the results to the nearest integer. As suggested, the distances between the nodes were calculated after loading the data and placed in a matrix, so that during the subsequent evaluation of the problem, it was only necessary to read these values which reduced the cost of the operation of the algorithm.\n",
    "\n",
    "To solve the problem the local search algorithm (steepest) with move evaluations from previous iterations. We operate in edge-intra and inter neighbourhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXwJo02J9haN"
   },
   "source": [
    "## 2. Pseudocode of all implemented algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "function local_steepest_delta_reusing_search(solution, nodes, distance_matrix):\n",
    "    operations = generate_possible_operations(solution, len(nodes), neighborhood_type='edge')\n",
    "    operations_queue = PriorityQueue()\n",
    "    \n",
    "    for operation in operations:\n",
    "        delta = operation.evaluate(solution, nodes, distance_matrix)\n",
    "        if delta < 0:\n",
    "            operations_queue.put(operation)\n",
    "    \n",
    "    while not operations_queue.empty():\n",
    "        operation = operiations_queue.pop()\n",
    "        if not operation.is_applicable(solution):\n",
    "            continue\n",
    "\n",
    "        prev_solution = solution\n",
    "        solution = operation.apply(solution)\n",
    "\n",
    "        new_node_replacement_ops = get_new_node_replacement_ops(\n",
    "            operation, \n",
    "            nodes, \n",
    "            solution \n",
    "            distance_matrix\n",
    "        )\n",
    "\n",
    "        node_replacement_ops_for_reevaluation = get_node_replacement_ops_for_reevaluation(\n",
    "            operation, \n",
    "            nodes, \n",
    "            solution, \n",
    "            prev_solution, \n",
    "            distance_matrix\n",
    "        )    \n",
    "\n",
    "        edge_swap_ops_for_reevaluation = get_edge_swap_ops_for_reevaluation(\n",
    "            operation, \n",
    "            nodes, \n",
    "            solution, \n",
    "            prev_solution, \n",
    "            distance_matrix\n",
    "        )\n",
    "        all_ops_for_reevaluation = (\n",
    "            new_node_replacement_ops + \n",
    "            node_replacement_ops_for_reevaluation + \n",
    "            edge_swap_ops_for_reevaluation\n",
    "        )\n",
    "\n",
    "        for op in all_ops_for_reevaluation:\n",
    "            delta = op.evaluate(solution, nodes, distance_matrix)\n",
    "            if delta < 0:\n",
    "                operations_queue.put(op)\n",
    "\n",
    "    return solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuHHtRw49haO"
   },
   "source": [
    "## 3. Results of the computational experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HA3NCQgm9haO"
   },
   "source": [
    "### 3.1. Code for visualization of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhyuKXc79haP"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmY2J3gW9haQ"
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/'\n",
    "OLD_RESULTS_FOLDER = f'{DATA_FOLDER}old_results/'\n",
    "RESULT_FOLDER = f'{DATA_FOLDER}results/'\n",
    "INSTANCE_FOLDER = f'{DATA_FOLDER}tsp_instances/'\n",
    "\n",
    "SOLVERS = {\n",
    "    \"lsp-r\" : \"Steepest LS, edge (radom) (DELTA REUSING)\",\n",
    "}\n",
    "\n",
    "OLD_SOLVERS = {\n",
    "    'd': \"Greedy Heuristic\",\n",
    "    'lsgedge-d' : \"Greedy LS, edge (GH)\",\n",
    "    \"lsc-10-r\" : \"Steepest LS, with (10) Candidates\",\n",
    "    \"lsc-20-r\" : \"Steepest LS, with (20) Candidates\",\n",
    "    'lssedge-d' : \"Steepest LS, edge (GH)\",\n",
    "    'lssedge-r' : \"Steepest LS, edge (random) (BASELINE)\",\n",
    "}\n",
    "SOLVERS_TO_PLOT = SOLVERS.copy()\n",
    "SOLVERS_TO_PLOT.update({\"lssedge-r\": OLD_SOLVERS[\"lssedge-r\"], \"lsc-10-r\": OLD_SOLVERS[\"lsc-10-r\"], \"d\": OLD_SOLVERS[\"d\"]})\n",
    "SOLVERS_TO_DRAW = {\"lsp-r\": SOLVERS[\"lsp-r\"], \"lssedge-r\": OLD_SOLVERS[\"lssedge-r\"]}\n",
    "SOLVERS = {**OLD_SOLVERS, **SOLVERS}\n",
    "NUM_NODES = 200\n",
    "\n",
    "instance_files = [path for path in pathlib.Path(INSTANCE_FOLDER).iterdir() if path.is_file()]\n",
    "instance_names = [path.name[:4] for path in instance_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mR3Bfr4w9haQ"
   },
   "outputs": [],
   "source": [
    "instances_data = {\n",
    "    name: read_instance(f'{INSTANCE_FOLDER}{name}.csv')\n",
    "    for name in instance_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcmhV8nH9haQ"
   },
   "outputs": [],
   "source": [
    "instances_solvers_pairs = itertools.product(instances_data.keys(), SOLVERS.keys())\n",
    "\n",
    "all_results = {}\n",
    "all_costs = {}\n",
    "all_times = {}\n",
    "all_stats = {}\n",
    "\n",
    "for instance, solver in instances_solvers_pairs:\n",
    "    all_results[instance] = all_results.get(instance, {})\n",
    "    all_costs[instance] = all_costs.get(instance, {})\n",
    "    all_times[instance] = all_times.get(instance, {})\n",
    "    all_stats[instance] = all_stats.get(instance, {})\n",
    "    costs = []\n",
    "    times = []\n",
    "    paring_results = []\n",
    "    for idx in range(NUM_NODES):\n",
    "        folder = OLD_RESULTS_FOLDER if solver in OLD_SOLVERS else RESULT_FOLDER\n",
    "        solution, cost, time = read_solution(f'{folder}{instance}-{solver}-{idx}.txt')\n",
    "        paring_results.append(solution)\n",
    "        costs.append(cost)\n",
    "        times.append(time)\n",
    "    all_results[instance][solver] = np.array(paring_results)\n",
    "    all_costs[instance][solver] = np.array(costs)\n",
    "    all_stats[instance][solver] = {\n",
    "        'mean': np.mean(costs),\n",
    "        'std': np.std(costs),\n",
    "        'min': np.min(costs),\n",
    "        'max': np.max(costs),\n",
    "    }\n",
    "    all_times[instance][solver] = {\n",
    "        'mean': np.mean(times),\n",
    "        'std': np.std(times),\n",
    "        'min': np.min(times),\n",
    "        'max': np.max(times),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zy6WhlM9haR"
   },
   "outputs": [],
   "source": [
    "costs_df = pd.DataFrame(all_stats).T\n",
    "time_df = pd.DataFrame(all_times).T\n",
    "max_df = pd.DataFrame(all_stats).T\n",
    "min_df = pd.DataFrame(all_stats).T\n",
    "mean_time_df = pd.DataFrame(all_times).T\n",
    "\n",
    "for column in SOLVERS.keys():\n",
    "    costs_df[column] = costs_df[column].apply(lambda x: f'{x[\"mean\"]:.0f} ({x[\"min\"]:.0f} - {x[\"max\"]:.0f})')\n",
    "    time_df[column] = time_df[column].apply(lambda x: f'{x[\"mean\"]/1000:.2f} ({x[\"min\"]/1000:.2f} - {x[\"max\"]/1000:.2f})')\n",
    "    max_df[column] = max_df[column].apply(lambda x: x['max'])\n",
    "    min_df[column] = min_df[column].apply(lambda x: x['min'])\n",
    "    mean_time_df[column] = mean_time_df[column].apply(lambda x: x['mean']/1000)\n",
    "\n",
    "for df in [costs_df, time_df, max_df, min_df, mean_time_df]:\n",
    "    df.rename(columns=SOLVERS, inplace=True)\n",
    "time_df = time_df.filter(items = SOLVERS_TO_PLOT.values())\n",
    "mean_time_df = mean_time_df.filter(items  = SOLVERS_TO_PLOT.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wo5of3599haR"
   },
   "source": [
    "### 3.2. Visualizations and statistics of cost for all dataset-algorithm pairs\n",
    "\n",
    "In tabular form we present the Mean, Minimum and Maximum of the results of the algorithms for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhTk45H69haR"
   },
   "outputs": [],
   "source": [
    "print(\"Mean (min-max) of the costs:\")\n",
    "\n",
    "best_means = {\n",
    "    instance: min(all_stats[instance][solver]['mean'] for solver in SOLVERS.keys())\n",
    "    for instance in instance_names\n",
    "}\n",
    "\n",
    "def apply_style(v: str, best_val: float):\n",
    "    num = v.split()[0]\n",
    "    try:\n",
    "        num = float(num)\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "    if round(num) == round(best_val):\n",
    "        return \"font-weight: bold; color: red\"\n",
    "    return \"\"\n",
    "    \n",
    "\n",
    "\n",
    "costs_df.T.style.apply(lambda x: [\n",
    "    apply_style(v, best_means[x.index[i]])\n",
    "    for i, v in enumerate(x)\n",
    "], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fasltPV99haR"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 8), sharey=True)\n",
    "\n",
    "for idx, instance in enumerate(instances_data.keys()):\n",
    "    if idx%2 == 0:\n",
    "        axs[(idx//2)%2][idx%2].set_ylabel('Cost')\n",
    "    axs[(idx//2)%2][idx%2].set_title(instance)\n",
    "\n",
    "    axs[(idx//2)%2][idx%2].violinplot(\n",
    "        [all_costs[instance][solver] for solver in SOLVERS_TO_PLOT.keys()],\n",
    "        showmeans=True,\n",
    "    )\n",
    "\n",
    "    axs[(idx//2)%2][idx%2].set_xticks(range(1, len(SOLVERS_TO_PLOT.keys()) + 1))\n",
    "    if idx > 1:\n",
    "        axs[(idx//2)%2][idx%2].set_xticklabels(SOLVERS_TO_PLOT.values(), rotation=45, ha='right')\n",
    "    else :\n",
    "        axs[(idx//2)%2][idx%2].set_xticklabels([])\n",
    "\n",
    "plt.suptitle('Distribution of the costs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3.3. Visualizations and statistics of running times for all dataset-algorithm pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean (min-max) of the time [ms]:\")\n",
    "\n",
    "best_times = {\n",
    "    instance: min(all_times[instance][solver]['mean'] for solver in SOLVERS_TO_PLOT.keys()) / 1000\n",
    "    for instance in instance_names\n",
    "}\n",
    "\n",
    "def apply_style(v: str, best_val: float):\n",
    "    num = v.split()[0]\n",
    "    try:\n",
    "        num = float(num)\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "    if round(num) == round(best_val):\n",
    "        return \"font-weight: bold; color: red\"\n",
    "    return \"\"\n",
    "    \n",
    "\n",
    "\n",
    "time_df.T.style.apply(lambda x: [\n",
    "    apply_style(v, best_times[x.index[i]])\n",
    "    for i, v in enumerate(x)\n",
    "], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.arange(len(SOLVERS_TO_PLOT))\n",
    "bar_width = 0.8 / len(instances_data.keys())\n",
    "mean_time_plot_df = mean_time_df.T.sort_values(by=\"TSPA\", ascending=False).T\n",
    "fig, ax = plt.subplots(figsize=(15, 8), sharey=True)\n",
    "for idx, instance in enumerate(instances_data.keys()):\n",
    "     ax.bar(\n",
    "          x_range + idx * bar_width,\n",
    "          height=mean_time_plot_df.loc[instance].values,\n",
    "          width=bar_width,\n",
    "          label=instance,\n",
    "     )\n",
    "ax.set_xticks(x_range + bar_width * (len(instances_data.keys()) - 1) / 2)\n",
    "ax.set_xticklabels(mean_time_plot_df.columns, rotation=45, ha='right')\n",
    "plt.title('Time per instance per solver')\n",
    "plt.ylabel('Running Time [ms]')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FgpBbE19haS"
   },
   "source": [
    "## 4. Best solutions for all datasets and algorithms\n",
    "\n",
    "To more easily compare the results, we present the best solutions for each dataset side by side.\n",
    "\n",
    "The weight of each node is denoted both by its size and color. The bigger and brighter the node, the higher its weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 New algortithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Gqoff_69haS"
   },
   "outputs": [],
   "source": [
    "for solver_idx, solver in enumerate(SOLVERS_TO_DRAW.keys()):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    for idx, instance in enumerate(instances_data.keys()):\n",
    "        best_instance_idx = np.argmin(all_costs[instance][solver])\n",
    "        plot_solution_for_instance(instances_data[instance], all_results[instance][solver][best_instance_idx], axs[idx])\n",
    "        axs[idx].set_title(f'{instance}: {all_costs[instance][solver][best_instance_idx]:.0f}')\n",
    "    fig.suptitle(f'{SOLVERS_TO_DRAW[solver]}', fontsize=16, y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Best solution for each instance from all algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for idx, instance in enumerate(instances_data.keys()):\n",
    "    best_cost =  np.inf\n",
    "    for solver_idx, solver in enumerate(SOLVERS.keys()):\n",
    "         if best_cost > np.min(all_costs[instance][solver]):\n",
    "                best_cost = np.min(all_costs[instance][solver])\n",
    "                best_result = all_results[instance][solver][np.argmin(all_costs[instance][solver])], \n",
    "                best_solver = solver\n",
    "    best_instance_idx = np.argmin(all_costs[instance][best_solver])\n",
    "    plot_solution_for_instance(instances_data[instance], all_results[instance][best_solver][best_instance_idx], axs[idx])\n",
    "    axs[idx].set_title(f'{instance}: {all_costs[instance][best_solver][best_instance_idx]:.0f}')\n",
    "    print(instance)\n",
    "    print(f'\\tSolver: {SOLVERS[best_solver]}, Total cost: {best_cost}')\n",
    "    zero_index = np.where(best_result[0] == 0)[0][0]\n",
    "    nodes = list(best_result[0][zero_index:])+list(best_result[0][:zero_index])\n",
    "    print(f'\\t Nodes: {nodes}\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YttFbeZ9haS"
   },
   "source": [
    "## 5. Source Code\n",
    "\n",
    "[GitHub](https://github.com/Tremirre/ECP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14ZLJh009haS"
   },
   "source": [
    "## 6. Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the results and visualizations, one can come to several conclusions about the algorithms used in the task:\n",
    "- **Time of running local search algorithm (steepest) with move evaluations (deltas) from previous iterations is greatly reduced** in comparison with its basic version. This is because there is no need to recalculate every possible potential move at each iteration, instead we check memorized moves from previous iterations. With these moves sorted by delta, we only need to find the first applicable move from the list.\n",
    "  \n",
    "- Results achieved by local search with move evaluations from previous iterations **are almost identical** to the basic version. Checking individual cases having a difference in solution, we discovered that they arise when there are at least two moves in a given iteration whose delta is equal and at the same time the best. Then the selection of different moves will cause the further path of the algorithm to look different. However, **the difference is ultimately almost negligible**. \n",
    "  \n",
    "- The program's execution time - dependently on the instance - can be **reduced by more than 50%**, but is still significantly outperformed (in terms of time efficiency) by Local Search with 10 Candidates."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
