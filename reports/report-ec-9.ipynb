{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd3jynF89haJ"
   },
   "source": [
    "# Evolutionary Computation - Assignment 9: Hybrid evolutionary algorithm\n",
    "Bartosz Stachowiak 148259<br>\n",
    "Andrzej Kajdasz 148273"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANGmPjsk9haM"
   },
   "source": [
    "## 1. Problem Statement\n",
    "\n",
    "There are columns of integers representing nodes. Each row corresponds to a node and contains its x and y coordinates in a plane, as well as a cost associated with the node. There were 4 such data sets each consisting of 200 rows (each representing a single node).\n",
    "\n",
    "Problem to solve is to choose precisely 50% of the nodes (rounding up if there is an odd number of nodes) and create a Hamiltonian cycle (a closed path) using this subset of nodes. The goal is to minimize the combined total length of the path and the total cost of the selected nodes.\n",
    "\n",
    "To calculate the distances between nodes, the Euclidean distance formula was used and then round the results to the nearest integer. As suggested, the distances between the nodes were calculated after loading the data and placed in a matrix, so that during the subsequent evaluation of the problem, it was only necessary to read these values which reduced the cost of the operation of the algorithm.\n",
    "\n",
    "To solve the problem the hybrid evolutionary algorithm were used with the following parameters:\n",
    "- Elite population - variable sizes from 5 to 75\n",
    "- Steady state algorithm\n",
    "- Parents selected from the population with the uniform probability\n",
    "- No copies of the same solution in the population (checked by comparing costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXwJo02J9haN"
   },
   "source": [
    "## 2. Pseudocode of all implemented algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "function generate_population(solution, nodes, distances, pop_size):\n",
    "    population = []\n",
    "    while len(population) < pop_size:\n",
    "        solution = generate_random_solution(nodes)\n",
    "        cost = evaluate(solution, nodes, distances)\n",
    "    \n",
    "        in_population = False\n",
    "        for instance in population:\n",
    "            if instance.cost == cost:\n",
    "                in_population = True\n",
    "                break\n",
    "\n",
    "        if not in_population:\n",
    "            population.append((solution, cost))\n",
    "\n",
    "    population.sort(key=lambda x: x[1])\n",
    "    return population\n",
    "\n",
    "\n",
    "function select_parents(population):\n",
    "    indices = shuffle(range(len(population)))\n",
    "    parent_1 = population[indices[0]]\n",
    "    parent_2 = population[indices[1]]\n",
    "    return parent_1, parent_2\n",
    "\n",
    "\n",
    "function edges_to_segments(edges):\n",
    "    segments = []\n",
    "    for edge in edges:\n",
    "        matching_segments = []\n",
    "        edge_cant_be_used = False\n",
    "\n",
    "        for segment in segments:\n",
    "\n",
    "            for i in range(1, len(segment) - 1):\n",
    "                if segment[i] in (edge[0], edge[1]):\n",
    "                    edge_cant_be_used = True\n",
    "                    break\n",
    "\n",
    "            if edge_cant_be_used:\n",
    "                break\n",
    "\n",
    "            if segment[0] in (edge[0], edge[1]) or segment[-1] in (edge[0], edge[1]):\n",
    "                matching_segments.append(segment)\n",
    "        \n",
    "        if edge_cant_be_used:\n",
    "            continue\n",
    "\n",
    "        if len(matching_segments) == 0:\n",
    "            segments.append(edge)\n",
    "        \n",
    "        elif len(matching_segments) == 1:\n",
    "            segment = matching_segments[0]\n",
    "            if segment[0] == edge[0]:\n",
    "                segment.insert(0, edge[1])\n",
    "            elif segment[0] == edge[1]:\n",
    "                segment.insert(0, edge[0])\n",
    "            elif segment[-1] == edge[0]:\n",
    "                segment.append(edge[1])\n",
    "            elif segment[-1] == edge[1]:\n",
    "                segment.append(edge[0])\n",
    "        \n",
    "        elif len(matching_segments) == 2:\n",
    "            segment_1 = matching_segments[0]\n",
    "            segment_2 = matching_segments[1]\n",
    "\n",
    "            if segment_1[0] == edge[0] or segment_1[0] == edge[1]:\n",
    "                segment_1.reverse()\n",
    "\n",
    "            if segment_2[0] == edge[0] or segment_2[0] == edge[1]:\n",
    "                segment_2.reverse()\n",
    "            \n",
    "            segment_1.extend(segment_2)\n",
    "            segments.remove(segment_2)\n",
    "        \n",
    "    return segments\n",
    "\n",
    "\n",
    "function recombine(parent_1, parent_2, nodes, distances):\n",
    "    p1_edges = set(sorted(parent_1[i], parent_1[(i + 1) % len(parent_1)]) for i in range(len(parent_1)))\n",
    "    p2_edges = set(sorted(parent_2[i], parent_2[(i + 1) % len(parent_2)]) for i in range(len(parent_2)))\n",
    "\n",
    "    common_edges = p1_edges.intersection(p2_edges)\n",
    "\n",
    "    # extract common edges into longest common segments\n",
    "    segments = edges_to_segments(common_edges)\n",
    "\n",
    "    shuffle(segments)\n",
    "\n",
    "    child = segments[0]\n",
    "    for segment in segments[1:]:\n",
    "        child.extend(segment)\n",
    "\n",
    "    solver = GreedyCycleSolver()\n",
    "    child = solver.solve(child, nodes, distances, len(nodes) // 2)\n",
    "\n",
    "    return child\n",
    "\n",
    "\n",
    "function genetic_local_search(solution, nodes, distances, max_time, local_search, pop_size):\n",
    "    \n",
    "    # population a sorted list of tuples (solution, cost)\n",
    "    population = generate_population(solution, nodes, distances, pop_size)\n",
    "\n",
    "    start_time = time()\n",
    "    iteration = 0\n",
    "\n",
    "    while time() - start_time < max_time:\n",
    "        iteration += 1\n",
    "\n",
    "        # sampled from the population with the uniform probability withou replacement\n",
    "        parent_1, parent_2 = select_parents(population)\n",
    "\n",
    "        child = recombine(parent_1, parent_2, nodes, distances)\n",
    "\n",
    "        if local_search:\n",
    "            child = local_search(child, nodes, distances)\n",
    "        \n",
    "        new_cost = evaluate(child, nodes, distances)\n",
    "        \n",
    "        in_population = False\n",
    "\n",
    "        for instance in population:\n",
    "            if instance.cost == new_cost:\n",
    "                in_population = True\n",
    "                break\n",
    "        \n",
    "        if new_cost < population[-1].cost and not in_population:\n",
    "            population[-1] = (child, new_cost)\n",
    "            population.sort(key=lambda x: x[1])\n",
    "\n",
    "    return population[0][0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuHHtRw49haO"
   },
   "source": [
    "## 3. Results of the computational experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhyuKXc79haP"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmY2J3gW9haQ"
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/'\n",
    "OLD_RESULTS_FOLDER = f'{DATA_FOLDER}old_results/'\n",
    "RESULT_FOLDER = f'{DATA_FOLDER}results/'\n",
    "INSTANCE_FOLDER = f'{DATA_FOLDER}tsp_instances/'\n",
    "\n",
    "SOLVERS = {\n",
    "    \"lseo-5-r\": \"Genetic LS, without post-recombine LS (Pop 5)\",\n",
    "    \"lseo-10-r\": \"Genetic LS, without post-recombine LS (Pop 10)\",\n",
    "    \"lseo-20-r\": \"Genetic LS, without post-recombine LS (Pop 20)\",\n",
    "    \"lseo-30-r\": \"Genetic LS, without post-recombine LS (Pop 30)\",\n",
    "    \"lseo-50-r\": \"Genetic LS, without post-recombine LS (Pop 50)\",\n",
    "    \"lseo-75-r\": \"Genetic LS, without post-recombine LS (Pop 75)\",\n",
    "    \"lsep-5-r\": \"Genetic LS, with steepest post-recombine LS (Pop 5)\",\n",
    "    \"lsep-10-r\": \"Genetic LS, with steepest post-recombine LS (Pop 10)\",\n",
    "    \"lsep-20-r\": \"Genetic LS, with steepest post-recombine LS (Pop 20)\",\n",
    "    \"lsep-30-r\": \"Genetic LS, with steepest post-recombine LS (Pop 30)\",\n",
    "    \"lsep-50-r\": \"Genetic LS, with steepest post-recombine LS (Pop 50)\",\n",
    "    \"lsep-75-r\": \"Genetic LS, with steepest post-recombine LS (Pop 75)\"\n",
    "}\n",
    "\n",
    "OLD_SOLVERS = {\n",
    "    \"lsnp-10-r\" : \"LNS Steepest LS (D10)\",\n",
    "    \"lsnp-20-r\" : \"LNS Steepest LS (D20)\",\n",
    "    \"lsnp-30-r\" : \"LNS Steepest LS (D30)\",\n",
    "    \"lsnp-50-r\" : \"LNS Steepest LS (D50)\",\n",
    "    \"lsnp-75-r\" : \"LNS Steepest LS (D75)\",\n",
    "    \"lsno-75-r\" : \"LNS no LS (D75)\",\n",
    "}\n",
    "\n",
    "OLD_SOLVERS_NO_ITER = {\n",
    "    \"lsm-r\" : \"Steepest Multi Start LS\",\n",
    "    \"lsi-10-r\" : \"Iterated LS (Perturbation size 10)\",\n",
    "    \"lsi-20-r\" : \"Iterated LS (Perturbation size 20)\",\n",
    "}\n",
    "SOLVERS_TO_PLOT = SOLVERS.copy()\n",
    "OLD_SOLVERS = {**OLD_SOLVERS_NO_ITER, **OLD_SOLVERS}\n",
    "SOLVERS = {**OLD_SOLVERS, **SOLVERS}\n",
    "NUM_NODES = 200\n",
    "\n",
    "instance_files = [path for path in pathlib.Path(INSTANCE_FOLDER).iterdir() if path.is_file()]\n",
    "instance_names = [path.name[:4] for path in instance_files]\n",
    "p_sizes = [5, 10, 20, 30, 50, 75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mR3Bfr4w9haQ"
   },
   "outputs": [],
   "source": [
    "instances_data = {\n",
    "    name: read_instance(f'{INSTANCE_FOLDER}{name}.csv')\n",
    "    for name in instance_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcmhV8nH9haQ"
   },
   "outputs": [],
   "source": [
    "instances_solvers_pairs = itertools.product(instances_data.keys(), SOLVERS.keys())\n",
    "\n",
    "all_results = {}\n",
    "all_costs = {}\n",
    "all_times = {}\n",
    "all_stats = {}\n",
    "all_no_iterations = {}\n",
    "\n",
    "for instance, solver in instances_solvers_pairs:\n",
    "    all_results[instance] = all_results.get(instance, {})\n",
    "    all_costs[instance] = all_costs.get(instance, {})\n",
    "    all_times[instance] = all_times.get(instance, {})\n",
    "    all_stats[instance] = all_stats.get(instance, {})\n",
    "    all_no_iterations[instance] = all_no_iterations.get(instance, {})\n",
    "    costs = []\n",
    "    times = []\n",
    "    paring_results = []\n",
    "    iterations = []\n",
    "    for idx in range(20):\n",
    "        folder = OLD_RESULTS_FOLDER if solver in OLD_SOLVERS else RESULT_FOLDER\n",
    "        if solver in OLD_SOLVERS_NO_ITER:\n",
    "            solution, cost, time = read_solution(f'{folder}{instance}-{solver}-{idx}.txt')\n",
    "        else:\n",
    "            solution, cost, time, no_iterations = read_solution_three_feature(f'{folder}{instance}-{solver}-{idx}.txt')\n",
    "            iterations.append(no_iterations)\n",
    "        paring_results.append(solution)\n",
    "        costs.append(cost)\n",
    "        times.append(time)\n",
    "        \n",
    "    all_results[instance][solver] = np.array(paring_results)\n",
    "    all_costs[instance][solver] = np.array(costs)\n",
    "    all_stats[instance][solver] = {\n",
    "        'mean': np.mean(costs),\n",
    "        'std': np.std(costs),\n",
    "        'min': np.min(costs),\n",
    "        'max': np.max(costs),\n",
    "    }\n",
    "    all_times[instance][solver] = {\n",
    "        'mean': np.mean(times),\n",
    "        'std': np.std(times),\n",
    "        'min': np.min(times),\n",
    "        'max': np.max(times),\n",
    "    }\n",
    "    if solver not in OLD_SOLVERS_NO_ITER:\n",
    "        all_no_iterations[instance][solver] = {\n",
    "            'mean': np.mean(iterations),\n",
    "            'std': np.std(iterations),\n",
    "            'min': np.min(iterations),\n",
    "            'max': np.max(iterations),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zy6WhlM9haR"
   },
   "outputs": [],
   "source": [
    "costs_df = pd.DataFrame(all_stats).T\n",
    "max_df = pd.DataFrame(all_stats).T\n",
    "min_df = pd.DataFrame(all_stats).T\n",
    "iterations_df = pd.DataFrame(all_no_iterations).T\n",
    "\n",
    "for column in SOLVERS.keys():\n",
    "    costs_df[column] = costs_df[column].apply(lambda x: f'{x[\"mean\"]:.0f} ({x[\"min\"]:.0f} - {x[\"max\"]:.0f})')\n",
    "    max_df[column] = max_df[column].apply(lambda x: x['max'])\n",
    "    min_df[column] = min_df[column].apply(lambda x: x['min'])\n",
    "    if column not in OLD_SOLVERS_NO_ITER:\n",
    "        iterations_df[column] = iterations_df[column].apply(lambda x: f'{x[\"mean\"]:.0f} ({x[\"min\"]:.0f} - {x[\"max\"]:.0f})')\n",
    "\n",
    "for df in [costs_df, max_df, min_df, iterations_df]:\n",
    "    df.rename(columns=SOLVERS, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wo5of3599haR"
   },
   "source": [
    "### 3.1. Visualizations and statistics of cost for all dataset-algorithm pairs\n",
    "\n",
    "In tabular form we present the Mean, Minimum and Maximum of the results of the algorithms for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhTk45H69haR"
   },
   "outputs": [],
   "source": [
    "print(\"Mean (min-max) of the costs:\")\n",
    "\n",
    "best_means = {\n",
    "    instance: min(all_stats[instance][solver]['mean'] for solver in SOLVERS.keys())\n",
    "    for instance in instance_names\n",
    "}\n",
    "\n",
    "def apply_style(v: str, best_val: float):\n",
    "    num = v.split()[0]\n",
    "    try:\n",
    "        num = float(num)\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "    if round(num) == round(best_val):\n",
    "        return \"font-weight: bold; color: red\"\n",
    "    return \"\"\n",
    "    \n",
    "\n",
    "\n",
    "costs_df.T.style.apply(lambda x: [\n",
    "    apply_style(v, best_means[x.index[i]])\n",
    "    for i, v in enumerate(x)\n",
    "], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Mean number of iterations\n",
    "\n",
    "Time limits:\n",
    "- TSPA: 9.12 s\n",
    "- TSPB: 8.62 s\n",
    "- TSPC: 6.5 s\n",
    "- TSPD: 5.4 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean (min-max) of the iterations:\")\n",
    "iterations_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3.3. Visualizations of the impact of population size on the iterations number and mean cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 11), sharex=True, sharey='row')\n",
    "\n",
    "for instance in instances_data.keys():\n",
    "    \n",
    "    axs[0][0].plot(\n",
    "        p_sizes,\n",
    "        [all_stats[instance][f\"lseo-{n}-r\"]['mean'] for n in p_sizes],\n",
    "        label=instance,\n",
    "        marker='o', \n",
    "        linestyle='dashed'\n",
    "    )\n",
    "    axs[0][1].plot(\n",
    "        p_sizes,\n",
    "        [all_stats[instance][f\"lsep-{n}-r\"]['mean'] for n in p_sizes],\n",
    "        label=instance,\n",
    "        marker='o', \n",
    "        linestyle='dashed'\n",
    "    )\n",
    "    axs[1][0].plot(\n",
    "        p_sizes,\n",
    "        [all_no_iterations[instance][f\"lseo-{n}-r\"]['mean'] for n in p_sizes],\n",
    "        label=instance,\n",
    "        marker='o', \n",
    "        linestyle='dashed'\n",
    "    )\n",
    "    axs[1][1].plot(\n",
    "        p_sizes,\n",
    "        [all_no_iterations[instance][f\"lsep-{n}-r\"]['mean'] for n in p_sizes],\n",
    "        label=instance,\n",
    "        marker='o', \n",
    "        linestyle='dashed'\n",
    "    )\n",
    "\n",
    "plt.suptitle(f'Genetic LS stats per population size')\n",
    "\n",
    "axs[0][0].set_title(\"Mean cost (no post-recombine LS)\")\n",
    "axs[0][0].set_xlabel('Size of population')\n",
    "axs[0][0].set_ylabel('Mean cost')\n",
    "\n",
    "axs[0][1].set_title('Mean cost (with post-recombine LS)')\n",
    "axs[0][1].set_xlabel('Size of population')\n",
    "axs[0][1].set_ylabel('Mean cost')\n",
    "\n",
    "axs[1][0].set_title('Mean number of iterations (no post-recombine LS)')\n",
    "axs[1][0].set_xlabel('Size of population')\n",
    "axs[1][0].set_ylabel('Number of iterations')\n",
    "\n",
    "axs[1][1].set_title('Mean number of iterations (with post-recombine LS)')\n",
    "axs[1][1].set_xlabel('Size of population')\n",
    "axs[1][1].set_ylabel('Number of iterations')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FgpBbE19haS"
   },
   "source": [
    "## 4. Best solutions for all datasets and algorithms\n",
    "\n",
    "To more easily compare the results, we present the best solutions for each dataset side by side.\n",
    "\n",
    "The weight of each node is denoted both by its size and color. The bigger and brighter the node, the higher its weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 New algortithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Gqoff_69haS"
   },
   "outputs": [],
   "source": [
    "for solver_idx, solver in enumerate(SOLVERS_TO_PLOT.keys()):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    for idx, instance in enumerate(instances_data.keys()):\n",
    "        best_instance_idx = np.argmin(all_costs[instance][solver])\n",
    "        plot_solution_for_instance(instances_data[instance], all_results[instance][solver][best_instance_idx], axs[idx])\n",
    "        axs[idx].set_title(f'{instance}: {all_costs[instance][solver][best_instance_idx]:.0f}')\n",
    "    fig.suptitle(f'{SOLVERS[solver]}', fontsize=16, y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Best solution for each instance from all algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for idx, instance in enumerate(instances_data.keys()):\n",
    "    best_cost =  np.inf\n",
    "    for solver_idx, solver in enumerate(SOLVERS.keys()):\n",
    "         if best_cost > np.min(all_costs[instance][solver]):\n",
    "                best_cost = np.min(all_costs[instance][solver])\n",
    "                best_result = all_results[instance][solver][np.argmin(all_costs[instance][solver])], \n",
    "                best_solver = solver\n",
    "    best_instance_idx = np.argmin(all_costs[instance][best_solver])\n",
    "    plot_solution_for_instance(instances_data[instance], all_results[instance][best_solver][best_instance_idx], axs[idx])\n",
    "    axs[idx].set_title(f'{instance}: {all_costs[instance][best_solver][best_instance_idx]:.0f}')\n",
    "    print(instance)\n",
    "    print(f'\\tSolver: {SOLVERS[best_solver]}, Total cost: {best_cost}')\n",
    "    nodes = list(best_result[0])\n",
    "    if 0 in best_result[0]:\n",
    "        zero_index = np.where(best_result[0] == 0)[0][0]\n",
    "        nodes = list(best_result[0][zero_index:])+list(best_result[0][:zero_index])\n",
    "    print(f'\\t Nodes: {nodes}\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YttFbeZ9haS"
   },
   "source": [
    "## 5. Source Code\n",
    "\n",
    "[GitHub](https://github.com/Tremirre/ECP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14ZLJh009haS"
   },
   "source": [
    "## 6. Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the results and visualizations, one can come to several conclusions about the algorithms used in the task:\n",
    "- **Genetic Local Search without post-recombine Local Search** achieved **worse results on average** than all previewed alternatives.\n",
    "- Genetic Local Search with post-recombine Local Search achieved better mean results than Steepest Multi Start Local Search, Iterated Local Search for all instances. Compared to LNS with Steepest LS, the results achieved are comparable and vary depending on the instance. For TSPA, TSPC and TSPD, Large Neighbourhood Search was better, but the difference between the best mean results obtained by the two algorithms does not exceed 1000. In TSPB, Genetic LS achieved better results but the improvement is small (<1%).\n",
    "- GLS has failed to find better solutions overall than LNS. \n",
    "- Post-recombination local search in GLS significantly improves performance of the algorithm. \n",
    "- The mean cost of the solutions found by GLS with post-recombine LS **decreases with the increase of the population size** (albeit only by a small margin), with best performance observed for pop size of 5. On the contrary, the mean cost of the solutions found by GLS without post-recombine LS **increases with the increase of the population size**. \n",
    "- The mean number of iterations **decreases with the increase of the population size** for both GLS with and without post-recombine LS.\n",
    "- The mean number of iterations for GLS with post-recombine LS is **significantly lower** than for GLS without post-recombine LS due to additional local search on each iteration."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
